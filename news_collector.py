"""
ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ ìˆ˜ì§‘
"""

import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import time
import re

class NewsCollector:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        self.session = requests.Session()

        # ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ ì‚¬ì „
        self.positive_keywords = [
            'ê¸‰ë“±', 'ìƒìŠ¹', 'í˜¸ì¬', 'ì‹ ê³ ê°€', 'ê°•ì„¸', 'ì¦ê°€', 'ì„±ì¥', 'í™•ëŒ€',
            'ìˆ˜ì£¼', 'ê³„ì•½', 'í‘ì', 'ê°œì„ ', 'ëŒíŒŒ', 'ìƒìŠ¹ì„¸', 'ë ë¦¬', 'ìµœê³ ',
            'ê¸ì •', 'í˜¸ì¡°', 'ìƒí–¥', 'ëª©í‘œê°€', 'ë§¤ìˆ˜', 'íˆ¬ìì˜ê²¬'
        ]

        self.negative_keywords = [
            'ê¸‰ë½', 'í•˜ë½', 'ì•…ì¬', 'ì‹ ì €ê°€', 'ì•½ì„¸', 'ê°ì†Œ', 'ì¶•ì†Œ', 'ì ì',
            'ë¶€ì§„', 'ìš°ë ¤', 'ê²½ê³ ', 'í•˜ë½ì„¸', 'ìµœì €', 'ë¶€ì •', 'í•˜í–¥', 'ë§¤ë„',
            'ì†ì‹¤', 'ì ì', 'íŒŒì‚°', 'êµ¬ì¡°ì¡°ì •'
        ]

    def _parse_news_time(self, time_str):
        """ë‰´ìŠ¤ ì‹œê°„ íŒŒì‹± (ì˜ˆ: '2024.01.28 07:30' ë˜ëŠ” '07:30')"""
        try:
            now = datetime.now()

            # "2024.01.28 07:30" í˜•ì‹
            if '.' in time_str:
                return datetime.strptime(time_str, '%Y.%m.%d %H:%M')
            # "07:30" í˜•ì‹ (ì˜¤ëŠ˜)
            elif ':' in time_str:
                time_parts = time_str.split(':')
                hour = int(time_parts[0])
                minute = int(time_parts[1])
                return now.replace(hour=hour, minute=minute, second=0, microsecond=0)
        except Exception:
            return None

    def _is_relevant_time(self, pub_time_str):
        """ì „ì¼ 18:00 ~ ë‹¹ì¼ 08:30 ì‚¬ì´ ë‰´ìŠ¤ì¸ì§€ í™•ì¸"""
        news_time = self._parse_news_time(pub_time_str)
        if not news_time:
            return True  # ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨ ì‹œ í¬í•¨

        now = datetime.now()
        yesterday_18 = (now - timedelta(days=1)).replace(hour=18, minute=0, second=0, microsecond=0)
        today_0830 = now.replace(hour=8, minute=30, second=0, microsecond=0)

        return yesterday_18 <= news_time <= today_0830

    def _analyze_sentiment(self, text):
        """ë‰´ìŠ¤ ê°ì„± ë¶„ì„ (ê¸ì •/ë¶€ì •/ì¤‘ë¦½)"""
        positive_count = sum(1 for keyword in self.positive_keywords if keyword in text)
        negative_count = sum(1 for keyword in self.negative_keywords if keyword in text)

        if positive_count > negative_count:
            return 'positive', positive_count - negative_count
        elif negative_count > positive_count:
            return 'negative', negative_count - positive_count
        else:
            return 'neutral', 0

    def get_stock_news(self):
        """ë„¤ì´ë²„ ê¸ˆìœµ ì£¼ìš” ë‰´ìŠ¤ ìˆ˜ì§‘ (ì‹œê°„ í•„í„°ë§ + ê°ì„± ë¶„ì„)"""
        print("ğŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")

        all_news = []

        try:
            # ë„¤ì´ë²„ ê¸ˆìœµ ì¦ì‹œ ë‰´ìŠ¤
            url = 'https://finance.naver.com/news/news_list.naver?mode=LSS3D&section_id=101&section_id2=258&section_id3=401'

            response = self.session.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')

            # ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ (2026ë…„ êµ¬ì¡° ë³€ê²½ ëŒ€ì‘)
            news_list = soup.find('ul', {'class': 'realtimeNewsList'})

            if news_list:
                # dd íƒœê·¸ì—ì„œ ë‰´ìŠ¤ ì¶”ì¶œ
                subjects = news_list.find_all('dd', {'class': 'articleSubject'})
                summaries = news_list.find_all('dd', {'class': 'articleSummary'})

                for i, subject in enumerate(subjects):
                    try:
                        title_tag = subject.find('a')
                        if not title_tag:
                            continue

                        title = title_tag.text.strip()
                        link = 'https://finance.naver.com' + title_tag.get('href', '')

                        # ìš”ì•½ ë° ì‹œê°„
                        summary = ''
                        pub_time = ''
                        if i < len(summaries):
                            summary_dd = summaries[i]
                            # ìš”ì•½ í…ìŠ¤íŠ¸ (span ì œì™¸)
                            for text in summary_dd.stripped_strings:
                                if text and not text in ['ì—°í•©ë‰´ìŠ¤TV', 'ë§¤ì¼ê²½ì œ', 'ì„œìš¸ê²½ì œ', 'í•œêµ­ê²½ì œ', 'ì´ë°ì¼ë¦¬', 'íŒŒì´ë‚¸ì…œë‰´ìŠ¤', '|']:
                                    summary = text
                                    break

                            # ì‹œê°„
                            time_tag = summary_dd.find('span', {'class': 'wdate'})
                            pub_time = time_tag.text.strip() if time_tag else ''

                        # ì‹œê°„ í•„í„°ë§ (ì „ì¼ 18:00 ~ ë‹¹ì¼ 08:30)
                        if not self._is_relevant_time(pub_time):
                            continue

                        # ê°ì„± ë¶„ì„
                        full_text = title + ' ' + summary
                        sentiment, score = self._analyze_sentiment(full_text)

                        all_news.append({
                            'title': title,
                            'summary': summary,
                            'link': link,
                            'pub_time': pub_time,
                            'source': 'naver_stock',
                            'sentiment': sentiment,
                            'sentiment_score': score
                        })

                    except Exception as e:
                        continue

            print(f"  âœ“ ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤: {len(all_news)}ê°œ (ì‹œê°„ í•„í„°ë§ ì ìš©)")

        except Exception as e:
            print(f"  âš ï¸  ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

        # ì¶”ê°€ ë‰´ìŠ¤ ì†ŒìŠ¤ (ì¦ê¶Œì‚¬ ë¦¬ì„œì¹˜, íŠ¹ì§•ì£¼ ë“±)
        try:
            # íŠ¹ì§•ì£¼ ë‰´ìŠ¤
            url = 'https://finance.naver.com/news/news_list.naver?mode=LSS3D&section_id=101&section_id2=258&section_id3=402'

            response = self.session.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')

            news_list = soup.find('ul', {'class': 'realtimeNewsList'})

            if news_list:
                # dd íƒœê·¸ì—ì„œ ë‰´ìŠ¤ ì¶”ì¶œ
                subjects = news_list.find_all('dd', {'class': 'articleSubject'})
                summaries = news_list.find_all('dd', {'class': 'articleSummary'})

                # ìƒìœ„ 30ê°œ
                for i, subject in enumerate(subjects[:30]):
                    try:
                        title_tag = subject.find('a')
                        if not title_tag:
                            continue

                        title = title_tag.text.strip()
                        link = 'https://finance.naver.com' + title_tag.get('href', '')

                        # ìš”ì•½ ë° ì‹œê°„
                        summary = ''
                        pub_time = ''
                        if i < len(summaries):
                            summary_dd = summaries[i]
                            # ìš”ì•½ í…ìŠ¤íŠ¸ (span ì œì™¸)
                            for text in summary_dd.stripped_strings:
                                if text and not text in ['ì—°í•©ë‰´ìŠ¤TV', 'ë§¤ì¼ê²½ì œ', 'ì„œìš¸ê²½ì œ', 'í•œêµ­ê²½ì œ', 'ì´ë°ì¼ë¦¬', 'íŒŒì´ë‚¸ì…œë‰´ìŠ¤', '|']:
                                    summary = text
                                    break

                            # ì‹œê°„
                            time_tag = summary_dd.find('span', {'class': 'wdate'})
                            pub_time = time_tag.text.strip() if time_tag else ''

                        # ì‹œê°„ í•„í„°ë§
                        if not self._is_relevant_time(pub_time):
                            continue

                        # ê°ì„± ë¶„ì„
                        full_text = title + ' ' + summary
                        sentiment, score = self._analyze_sentiment(full_text)

                        all_news.append({
                            'title': title,
                            'summary': summary,
                            'link': link,
                            'pub_time': pub_time,
                            'source': 'naver_featured',
                            'sentiment': sentiment,
                            'sentiment_score': score
                        })

                    except Exception as e:
                        continue

            print(f"  âœ“ íŠ¹ì§•ì£¼ ë‰´ìŠ¤: {len(all_news)}ê°œ (ëˆ„ì )")

        except Exception as e:
            print(f"  âš ï¸  íŠ¹ì§•ì£¼ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

        # ê¸ì • ë‰´ìŠ¤ í†µê³„
        positive_count = sum(1 for n in all_news if n.get('sentiment') == 'positive')
        negative_count = sum(1 for n in all_news if n.get('sentiment') == 'negative')
        neutral_count = sum(1 for n in all_news if n.get('sentiment') == 'neutral')

        print(f"  âœ“ ì´ {len(all_news)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
        print(f"    - ê¸ì •: {positive_count}ê°œ | ì¤‘ë¦½: {neutral_count}ê°œ | ë¶€ì •: {negative_count}ê°œ")

        return all_news

    def count_stock_mentions(self, stock_name, news_list):
        """íŠ¹ì • ì¢…ëª©ì´ ë‰´ìŠ¤ì— ì–¸ê¸‰ëœ íšŸìˆ˜ ê³„ì‚°"""
        count = 0

        for news in news_list:
            title = news.get('title', '')
            summary = news.get('summary', '')

            if stock_name in title or stock_name in summary:
                count += 1

        return count

    def extract_keywords_from_news(self, news_list):
        """ë‰´ìŠ¤ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ"""
        from collections import Counter
        import config

        all_keywords = []

        for news in news_list:
            title = news.get('title', '')
            summary = news.get('summary', '')
            text = title + ' ' + summary

            # ì„¤ì •ëœ í…Œë§ˆ í‚¤ì›Œë“œ ì°¾ê¸°
            for theme, keywords in config.THEME_KEYWORDS.items():
                for keyword in keywords:
                    if keyword in text:
                        all_keywords.append((theme, keyword))

        # ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ í…Œë§ˆ
        theme_counter = Counter([theme for theme, _ in all_keywords])

        return theme_counter.most_common(10)


if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸
    collector = NewsCollector()
    news = collector.get_stock_news()

    print(f"\nâœ… ìˆ˜ì§‘ ì™„ë£Œ: {len(news)}ê°œ ë‰´ìŠ¤")

    if news:
        print("\nğŸ“° ìµœê·¼ ë‰´ìŠ¤ 5ê°œ:")
        for item in news[:5]:
            print(f"  - {item['title']}")
            print(f"    {item['pub_time']}")

        print("\nğŸ”¥ í•« í…Œë§ˆ:")
        keywords = collector.extract_keywords_from_news(news)
        for theme, count in keywords:
            print(f"  - {theme}: {count}íšŒ ì–¸ê¸‰")
