"""
ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ ìˆ˜ì§‘
"""

import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import time

class NewsCollector:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        self.session = requests.Session()

    def get_stock_news(self):
        """ë„¤ì´ë²„ ê¸ˆìœµ ì£¼ìš” ë‰´ìŠ¤ ìˆ˜ì§‘"""
        print("ğŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")

        all_news = []

        try:
            # ë„¤ì´ë²„ ê¸ˆìœµ ì¦ì‹œ ë‰´ìŠ¤
            url = 'https://finance.naver.com/news/news_list.naver?mode=LSS3D&section_id=101&section_id2=258&section_id3=401'

            response = self.session.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')

            # ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
            news_list = soup.find('ul', {'class': 'newsList'})

            if news_list:
                items = news_list.find_all('li')

                for item in items:
                    try:
                        title_tag = item.find('a', {'class': 'tit'})
                        if not title_tag:
                            continue

                        title = title_tag.text.strip()
                        link = 'https://finance.naver.com' + title_tag.get('href', '')

                        # ìš”ì•½
                        summary_tag = item.find('span', {'class': 'txt'})
                        summary = summary_tag.text.strip() if summary_tag else ''

                        # ì‹œê°„
                        time_tag = item.find('span', {'class': 'wdate'})
                        pub_time = time_tag.text.strip() if time_tag else ''

                        all_news.append({
                            'title': title,
                            'summary': summary,
                            'link': link,
                            'pub_time': pub_time,
                            'source': 'naver_stock'
                        })

                    except Exception as e:
                        continue

            print(f"  âœ“ ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤: {len(all_news)}ê°œ")

        except Exception as e:
            print(f"  âš ï¸  ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

        # ì¶”ê°€ ë‰´ìŠ¤ ì†ŒìŠ¤ (ì¦ê¶Œì‚¬ ë¦¬ì„œì¹˜, íŠ¹ì§•ì£¼ ë“±)
        try:
            # íŠ¹ì§•ì£¼ ë‰´ìŠ¤
            url = 'https://finance.naver.com/news/news_list.naver?mode=LSS3D&section_id=101&section_id2=258&section_id3=402'

            response = self.session.get(url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')

            news_list = soup.find('ul', {'class': 'newsList'})

            if news_list:
                items = news_list.find_all('li')

                for item in items[:20]:  # ìƒìœ„ 20ê°œë§Œ
                    try:
                        title_tag = item.find('a', {'class': 'tit'})
                        if not title_tag:
                            continue

                        title = title_tag.text.strip()
                        link = 'https://finance.naver.com' + title_tag.get('href', '')

                        summary_tag = item.find('span', {'class': 'txt'})
                        summary = summary_tag.text.strip() if summary_tag else ''

                        time_tag = item.find('span', {'class': 'wdate'})
                        pub_time = time_tag.text.strip() if time_tag else ''

                        all_news.append({
                            'title': title,
                            'summary': summary,
                            'link': link,
                            'pub_time': pub_time,
                            'source': 'naver_featured'
                        })

                    except Exception as e:
                        continue

            print(f"  âœ“ íŠ¹ì§•ì£¼ ë‰´ìŠ¤: {len(all_news)}ê°œ (ëˆ„ì )")

        except Exception as e:
            print(f"  âš ï¸  íŠ¹ì§•ì£¼ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

        print(f"  âœ“ ì´ {len(all_news)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
        return all_news

    def count_stock_mentions(self, stock_name, news_list):
        """íŠ¹ì • ì¢…ëª©ì´ ë‰´ìŠ¤ì— ì–¸ê¸‰ëœ íšŸìˆ˜ ê³„ì‚°"""
        count = 0

        for news in news_list:
            title = news.get('title', '')
            summary = news.get('summary', '')

            if stock_name in title or stock_name in summary:
                count += 1

        return count

    def extract_keywords_from_news(self, news_list):
        """ë‰´ìŠ¤ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ"""
        from collections import Counter
        import config

        all_keywords = []

        for news in news_list:
            title = news.get('title', '')
            summary = news.get('summary', '')
            text = title + ' ' + summary

            # ì„¤ì •ëœ í…Œë§ˆ í‚¤ì›Œë“œ ì°¾ê¸°
            for theme, keywords in config.THEME_KEYWORDS.items():
                for keyword in keywords:
                    if keyword in text:
                        all_keywords.append((theme, keyword))

        # ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ í…Œë§ˆ
        theme_counter = Counter([theme for theme, _ in all_keywords])

        return theme_counter.most_common(10)


if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸
    collector = NewsCollector()
    news = collector.get_stock_news()

    print(f"\nâœ… ìˆ˜ì§‘ ì™„ë£Œ: {len(news)}ê°œ ë‰´ìŠ¤")

    if news:
        print("\nğŸ“° ìµœê·¼ ë‰´ìŠ¤ 5ê°œ:")
        for item in news[:5]:
            print(f"  - {item['title']}")
            print(f"    {item['pub_time']}")

        print("\nğŸ”¥ í•« í…Œë§ˆ:")
        keywords = collector.extract_keywords_from_news(news)
        for theme, count in keywords:
            print(f"  - {theme}: {count}íšŒ ì–¸ê¸‰")
